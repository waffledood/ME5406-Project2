{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Performances of all 5 Methods (Double DQN, Dueling DQN, A2C, PID, Human)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant libraries & defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Preprocessing function to resize agent's view of the environment & convert it into grayscale '''\n",
    "\n",
    "def preprocessing(obs, info):\n",
    "    # convert to grayscale\n",
    "    obs = cv2.cvtColor(obs, cv2.COLOR_BGR2GRAY)\n",
    "    # resize to [40,40]\n",
    "    obs = cv2.resize(obs, (40, 40), interpolation=cv2.INTER_AREA)\n",
    "    # add new axis to [1,40,40]\n",
    "    obs = obs[np.newaxis, :]\n",
    "    # extract values\n",
    "    info = np.array(list(info.values()))\n",
    "\n",
    "    info = info / 360\n",
    "    obs = obs / 255\n",
    "    return obs, info\n",
    "\n",
    "''' Preprocessing functions for Double DQN & Dueling DQN '''\n",
    "deg2rad = np.pi / 180\n",
    "steering_step1 = 1 * deg2rad\n",
    "steering_step2 = 2 * deg2rad\n",
    "steering_step4 = 4 * deg2rad\n",
    "steering_step8 = 8 * deg2rad\n",
    "action_map = (\n",
    "    [1, 0, 0],\n",
    "    [1, 0, steering_step1],\n",
    "    [1, 0, -steering_step1],\n",
    "    [1, 0, steering_step2],\n",
    "    [1, 0, -steering_step2],\n",
    "    [1, 0, steering_step4],\n",
    "    [1, 0, -steering_step4],\n",
    "    [1, 0, steering_step8],\n",
    "    [1, 0, -steering_step8],\n",
    ")\n",
    "num_actions = len(action_map)\n",
    "image_size = [1, 1, 40, 40]\n",
    "data_size = [1, 3]\n",
    "num_of_episodes = 10000\n",
    "sync_freq = 1\n",
    "exp_replay_size = 200\n",
    "batch_size = 200\n",
    "count = 0\n",
    "\n",
    "\n",
    "''' Users specify the number of episodes to test the models on '''\n",
    "numTestEpisodes = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries & dependencies for Double DQN \n",
    "\n",
    "from common.environment import Environment\n",
    "from dqn.dqn_agent import DQAgent\n",
    "\n",
    "# init Environment & Double DQN agent \n",
    "env = Environment(randomized=0)\n",
    "agent = DQAgent(\n",
    "    env,\n",
    "    num_of_episodes,\n",
    "    sync_freq,\n",
    "    exp_replay_size,\n",
    "    batch_size,\n",
    "    num_actions,\n",
    "    image_size,\n",
    "    data_size,\n",
    ")\n",
    "\n",
    "# init error stat\n",
    "error_list_DQN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleDQNTest():\n",
    "    epsilon = 0\n",
    "    # load model\n",
    "    agent.target_net.load_state_dict(torch.load(\"models/best_dqn.pt\"))\n",
    "    agent.q_net.load_state_dict(torch.load(\"models/best_dqn.pt\"))\n",
    "\n",
    "    # testing\n",
    "    for i in range(numTestEpisodes):\n",
    "        obs, info = env.reset()\n",
    "        obs, info = preprocessing(obs, info)\n",
    "        obs = obs[np.newaxis, :]\n",
    "        info = info[np.newaxis, :]\n",
    "        done = False\n",
    "        ep_len, rew = 0, 0\n",
    "\n",
    "        # init current error stat\n",
    "        current_error_DQN = []\n",
    "        while done != True and ep_len < 2000:\n",
    "            ep_len += 1\n",
    "            a = agent.get_action(obs, info, num_actions, epsilon)\n",
    "            obs, reward, done, info = env.step(action_map[a])\n",
    "            error_trans = info[\"d_center\"]\n",
    "            obs, info = preprocessing(obs, info)\n",
    "            obs = obs[np.newaxis, :]\n",
    "            info = info[np.newaxis, :]\n",
    "            rew += reward\n",
    "\n",
    "            # track current error stat \n",
    "            current_error_DQN.append(error_trans)\n",
    "        # track error stats\n",
    "        error_list_DQN.append(current_error_DQN)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Double DQN agent interact with the environment \n",
    "doubleDQNTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translational Error (Double DQN)\n",
    "x = np.arange(0, 2000*0.1, 0.1)\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm']\n",
    "\n",
    "for y_idx, y in enumerate(error_list_DQN):\n",
    "    y = np.array(y)\n",
    "\n",
    "    # to account for cases when agent ends episode earlier than 2000 steps\n",
    "    if len(y) != 2000:\n",
    "        y = np.concatenate((y, np.zeros(2000-len(y), dtype='int')))\n",
    "    plt.plot(x, y, colors[y_idx % len(colors)])\n",
    "    \n",
    "plt.title(\"Translational Error (Double DQN)\")\n",
    "plt.ylabel(\"Translational Error\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries & dependencies for Double DQN \n",
    "\n",
    "from common.environment import Environment\n",
    "from ddqn.ddqn_agent import DuelingDQNAgent\n",
    "\n",
    "sync_freq = 10\n",
    "\n",
    "\n",
    "# init Environment & Double DQN agent \n",
    "env = Environment(randomized=0)\n",
    "agent = DuelingDQNAgent(\n",
    "    env,\n",
    "    num_of_episodes,\n",
    "    sync_freq,\n",
    "    exp_replay_size,\n",
    "    batch_size,\n",
    "    num_actions,\n",
    "    image_size,\n",
    "    data_size,\n",
    ")\n",
    "\n",
    "# init error stat\n",
    "error_list_DDQN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duelingDQNTest():\n",
    "    epsilon = 0\n",
    "    # load model\n",
    "    agent.q_net.load_state_dict(torch.load(\"models/best_ddqn.pt\"))\n",
    "\n",
    "    # testing\n",
    "    for i in range(numTestEpisodes):\n",
    "        obs, info = env.reset()\n",
    "        obs, info = preprocessing(obs, info)\n",
    "        obs = obs[np.newaxis, :]\n",
    "        info = info[np.newaxis, :]\n",
    "        done = False\n",
    "        ep_len, rew = 0, 0\n",
    "\n",
    "        # init current error stat\n",
    "        current_error_DDQN = []\n",
    "        \n",
    "        while done != True and ep_len < 2000:\n",
    "            ep_len += 1\n",
    "            a = agent.get_action(obs, info, num_actions, epsilon)\n",
    "            obs, reward, done, info = env.step(action_map[a])\n",
    "            error_trans = info[\"d_center\"]\n",
    "            obs, info = preprocessing(obs, info)\n",
    "            obs = obs[np.newaxis, :]\n",
    "            info = info[np.newaxis, :]\n",
    "            rew += reward\n",
    "\n",
    "            # track current error stat \n",
    "            current_error_DDQN.append(error_trans)\n",
    "        # track error stats\n",
    "        error_list_DDQN.append(current_error_DDQN)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Dueling DQN agent interact with the environment \n",
    "duelingDQNTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translational Error (Dueling DQN)\n",
    "x = np.arange(0, 2000*0.1, 0.1)\n",
    "for y_idx, y in enumerate(error_list_DDQN):\n",
    "    y = np.array(y)\n",
    "\n",
    "    # to account for cases when agent ends episode earlier than 2000 steps\n",
    "    if len(y) != 2000:\n",
    "        y = np.concatenate((y, np.zeros(2000-len(y), dtype='int')))\n",
    "    plt.plot(x, y, colors[y_idx % len(colors)])\n",
    "    \n",
    "plt.title(\"Translational Error (Dueling DQN)\")\n",
    "plt.ylabel(\"Translational Error\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries & dependencies for A2C\n",
    "\n",
    "from common.environment2 import Environment2\n",
    "from a2c.a2c_agent import A2CAgent\n",
    "\n",
    "num_actions = 1\n",
    "image_size = [1, 1, 40, 40]\n",
    "data_size = [1, 3]\n",
    "num_of_episodes = 10000\n",
    "batch_size = 200\n",
    "beta = 0.001\n",
    "gamma = 0.95\n",
    "clip_grad = 0.1\n",
    "count = 0\n",
    "\n",
    "\n",
    "# init Environment & A2C agent \n",
    "env2 = Environment2(randomized=0)\n",
    "agent = A2CAgent(\n",
    "    env, num_of_episodes, beta, gamma, clip_grad, batch_size, num_actions, image_size, data_size\n",
    ")\n",
    "\n",
    "# init error stat\n",
    "error_list_A2C = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A2CTest():\n",
    "    agent.net.load_state_dict(torch.load(\"models/best_a2c.pt\"))\n",
    "\n",
    "    # test\n",
    "    for i in range(numTestEpisodes):\n",
    "        obs, info = env2.reset()\n",
    "        obs, info = preprocessing(obs, info)\n",
    "        obs = obs[np.newaxis, :]\n",
    "        info = info[np.newaxis, :]\n",
    "        done = False\n",
    "        ep_len, rew = 0, 0\n",
    "\n",
    "        # init current error stat\n",
    "        current_error_A2C = []\n",
    "\n",
    "        while done != True and ep_len < 2000:\n",
    "            ep_len += 1\n",
    "            a = agent.get_action(obs, info)\n",
    "            obs, reward, done, info = env2.step([1, 0, a.squeeze(0)])\n",
    "            error_trans = info[\"d_center\"]\n",
    "            obs, info = preprocessing(obs, info)\n",
    "            obs = obs[np.newaxis, :]\n",
    "            info = info[np.newaxis, :]\n",
    "            rew += reward\n",
    "\n",
    "            # track current error stat \n",
    "            current_error_A2C.append(error_trans)\n",
    "        # track error stats\n",
    "        error_list_A2C.append(current_error_A2C)\n",
    "\n",
    "    env2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let A2C agent interact with the environment \n",
    "A2CTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translational Error (A2C)\n",
    "x = np.arange(0, 2000*0.1, 0.1)\n",
    "for y_idx, y in enumerate(error_list_A2C):\n",
    "    y = np.array(y)\n",
    "\n",
    "    # to account for cases when agent ends episode earlier than 2000 steps\n",
    "    if len(y) != 2000:\n",
    "        y = np.concatenate((y, np.zeros(2000-len(y), dtype='int')))\n",
    "    plt.plot(x, y, colors[y_idx % len(colors)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PID Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.environment3 import Environment3\n",
    "\n",
    "# init helper variables, \n",
    "deg2rad = np.pi/180\n",
    "steering_step = 10*deg2rad\n",
    "\n",
    "# init environment \n",
    "env3 = Environment3(randomized=0)\n",
    "numTestEpisodes = 1 #10\n",
    "\n",
    "\n",
    "# PID parameters\n",
    "Kp = 0.001\n",
    "Ki = 0.00000000001\n",
    "Kd = 0.001 \n",
    "dt = 0.1\n",
    "\n",
    "# init error stat\n",
    "error_list_PID = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIDTest():\n",
    "    # begin driving\n",
    "    for i in range(numTestEpisodes):\n",
    "        obs, info = env3.reset()\n",
    "        done = False\n",
    "        ep_len, rew = 0, 0\n",
    "        a = [1, 0, 0]\n",
    "\n",
    "        # PID variables \n",
    "        P_error_trans, I_error_trans, D_error_trans = 0, 0, 0\n",
    "        # previous error, correction agent needs to make \n",
    "        prev_error_trans, corr_trans = 0, 0\n",
    "        \n",
    "        # init stats for current error\n",
    "        current_error = []\n",
    "\n",
    "        while(done != True and ep_len < 2000):\n",
    "\n",
    "            # take an action \n",
    "            obs, reward, done, info = env3.step(a)\n",
    "            \n",
    "            ''' info '''\n",
    "            velocity = info[\"velocity\"]\n",
    "            error_trans = info[\"d_center\"]\n",
    "            error_angle = info[\"d_angle\"]\n",
    "\n",
    "            ''' PID Controller '''\n",
    "            # P error (current error)\n",
    "            P_error_trans = error_trans\n",
    "\n",
    "            # I error (cumulative error) \n",
    "            # anti-windup for I error (when the controller has reached the setpoint, reset I error to 0) \n",
    "            if np.abs(error_trans) <= 0.1:\n",
    "                I_error_trans = 0\n",
    "            # else continue accumulating error \n",
    "            else:\n",
    "                I_error_trans = I_error_trans + error_trans\n",
    "\n",
    "            # D error (difference in errors)\n",
    "            D_error_trans = (error_trans - prev_error_trans)/dt \n",
    "\n",
    "            # PID control algo\n",
    "            corr_trans = Kp*P_error_trans + Ki*I_error_trans + Kd*D_error_trans\n",
    "\n",
    "            ''' Controller determines next action to take '''\n",
    "            # determine next action to take \n",
    "            a = [1, 0, corr_trans]\n",
    "\n",
    "            ''' Variable updating & Error tracking '''\n",
    "            # updating of variables \n",
    "            prev_error_trans = error_trans\n",
    "            ep_len += 1\n",
    "            rew  += reward\n",
    "        \n",
    "            # track current error stats\n",
    "            current_error.append(error_trans)\n",
    "        \n",
    "        # track stats\n",
    "        error_list_PID.append(current_error)\n",
    "\n",
    "    env3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let PID Controller interact with the environment \n",
    "PIDTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translational Error (PID Controller)\n",
    "x = np.arange(0, 2000*0.1, 0.1)\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm']\n",
    "\n",
    "for y_idx, y in enumerate(error_list_PID):\n",
    "    y = np.array(y)\n",
    "\n",
    "    # to account for cases when controller ends episode earlier than 2000 steps\n",
    "    if len(y) != 2000:\n",
    "        y = np.concatenate((y, np.zeros(2000-len(y), dtype='int')))\n",
    "    plt.plot(x, y, colors[y_idx % len(colors)])\n",
    "    \n",
    "plt.title(\"Translational Error (PID)\")\n",
    "plt.ylabel(\"Translational Error\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.environment import Environment\n",
    "\n",
    "env4 = Environment(randomized=0)\n",
    "\n",
    "ep_len = 0\n",
    "done = False\n",
    "\n",
    "# init error stat\n",
    "error_list_Human = []\n",
    "\n",
    "def humanTest():\n",
    "    for i in range(numTestEpisodes):\n",
    "        ep_len = 0\n",
    "        done = False\n",
    "        current_error_Human = []\n",
    "        \n",
    "        while done != True and ep_len < 2000:\n",
    "            action = env4.policy()\n",
    "\n",
    "            obs, reward, done, info = env4.step(action)\n",
    "            error_trans = info[\"d_center\"]\n",
    "\n",
    "            # print(reward, info)\n",
    "\n",
    "            # track current error stat \n",
    "            current_error_Human.append(error_trans)\n",
    "\n",
    "            if done:\n",
    "                env4.reset()\n",
    "            cv2.imshow(\"Observation Space\", obs)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            ep_len+=1 \n",
    "\n",
    "        # track error stats\n",
    "        error_list_Human.append(current_error_Human)\n",
    "\n",
    "        env4.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "now it's your turn to play! \n",
    "(& see how badly/well you perform)\n",
    "'''\n",
    "\n",
    "# Let Human interact with the environment \n",
    "humanTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translational Error (Human)\n",
    "x = np.arange(0, 2000*0.1, 0.1)\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm']\n",
    "\n",
    "for y_idx, y in enumerate(error_list_Human):\n",
    "    y = np.array(y)\n",
    "\n",
    "    # to account for cases when controller ends episode earlier than 2000 steps\n",
    "    if len(y) != 2000:\n",
    "        y = np.concatenate((y, np.zeros(2000-len(y), dtype='int')))\n",
    "    plt.plot(x, y, colors[y_idx % len(colors)])\n",
    "    \n",
    "plt.title(\"Translational Error (Human)\")\n",
    "plt.ylabel(\"Translational Error\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between all 5 methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "important note:\n",
    "each of the error_list_{model} in error_list_main is \n",
    "a *list of lists*. This is so users may specify the number \n",
    "of testing episodes to run all these models on & whether on the\n",
    "same or new environment each episode.\n",
    "\n",
    "The number of episodes to test for is defined in variable \n",
    "\n",
    "'''\n",
    "\n",
    "error_list_main = {\n",
    "    \"Double DQN\": error_list_DQN,\n",
    "    \"Dueling DQN\": error_list_DDQN,\n",
    "    \"A2C\": error_list_A2C,\n",
    "    \"PID\": error_list_PID,\n",
    "    \"Human\": error_list_Human\n",
    "}\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm']\n",
    "\n",
    "# for i in range(numTestEpisodes):\n",
    "for idx, error_list_key in enumerate(error_list_main):\n",
    "    if error_list_key == \"PID\":\n",
    "        plt.plot(x, savgol_filter(np.abs(error_list_main[error_list_key][0]), 51, 2), colors[idx], label=error_list_key)\n",
    "    else:\n",
    "        plt.plot(x, savgol_filter(error_list_main[error_list_key][0], 51, 2), colors[idx], label=error_list_key)\n",
    "\n",
    "plt.title(\"Translational Error (All 5 Methods)\")\n",
    "plt.ylabel(\"Translational Error\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the error data into `.json` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "important note:\n",
    "each of the error_list_{model} in error_list_json is \n",
    "a *list of lists*. This is so users may specify the number \n",
    "of testing episodes to run all these models on & whether on the\n",
    "same or new environment each episode.\n",
    "\n",
    "The number of episodes to test for is defined in variable \n",
    "\n",
    "'''\n",
    "\n",
    "error_list_json = {\n",
    "    \"dqn\": error_list_DQN,\n",
    "    \"ddqn\": error_list_DDQN,\n",
    "    \"a2c\": error_list_A2C,\n",
    "    \"pid\": error_list_PID,\n",
    "    \"human\": error_list_Human\n",
    "}\n",
    "\n",
    "for id, key in enumerate(error_list_json):\n",
    "    with open(f\"errors/{key}_errors.json\", \"w\") as f:\n",
    "        errors = {\n",
    "            \"errors\": error_list_json[key],\n",
    "        }\n",
    "        json.dump(errors, f, indent=2)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "185bd4aeb33b01c97611a16e11661855351b2848a021039db7d322aa5f73e029"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tensor': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
